# 工业检测系统核心功能使用指南

## 一、图像采集模块

### 1. 功能概述
图像采集模块是工业检测系统的基础，负责从多种图像源（USB摄像头、网络摄像头、视频文件等）获取高质量工业场景图像，支持实时预览、参数动态调整、图像保存和视频录制功能，为后续的智能检测和数据分析提供可靠的原始数据。

### 2. 使用方法

#### 2.1 摄像头连接与配置

##### 2.1.1 自动检测摄像头
- 系统启动时会自动调用 `cv2.VideoCapture()` 函数检测所有可用摄像头设备
- 检测结果会显示在「设备管理」页面，包括设备ID、名称、分辨率和连接状态
- 支持的摄像头类型：USB摄像头、内置摄像头、工业相机（需安装对应驱动）

##### 2.1.2 手动添加摄像头
1. 进入「设置」→「设备管理」页面
2. 点击「添加设备」按钮，打开设备添加对话框
3. 选择设备类型为「摄像头」
4. **填写基本信息**：
   - 摄像头名称：自定义名称（如"生产线摄像头1"）
   - 设备路径：
     - 本地摄像头：使用设备索引（如`0`、`1`）或设备文件路径（如`/dev/video0`）
     - 网络摄像头：使用RTSP/HTTP URL（如`rtsp://192.168.1.100:554/stream1`）
   - 设备类型：根据实际设备选择（通用USB、工业相机、网络相机）
5. **高级配置**（可选）：
   - 连接超时：设置摄像头连接的最大等待时间（默认5秒）
   - 自动重连：启用后，摄像头断开连接时系统会自动尝试重新连接
6. 点击「保存」完成添加，系统会立即尝试连接并验证摄像头可用性

##### 2.1.3 摄像头参数调整
在「实时监控」页面，点击摄像头预览区域，右侧会显示完整的参数调整面板：

| 参数名称 | 可调整范围 | 默认值 | 说明 | 最佳实践 |
|---------|-----------|-------|------|---------|
| 分辨率（Resolution） | 支持摄像头的所有分辨率 | 1280×720 | 图像的宽度和高度像素数 | 根据检测需求选择：字符检测建议≥1920×1080，缺陷检测建议≥1280×720 |
| 帧率（Frame Rate） | 5-60 FPS | 30 FPS | 每秒采集的图像数量 | 实时检测建议25-30 FPS，定时采集可降低至5-10 FPS以减少存储占用 |
| 曝光（Exposure） | 自动/1-100000微秒 | 自动 | 摄像头传感器的曝光时间 | 低光照环境下增加曝光时间，避免过曝；高速运动物体需减小曝光时间避免模糊 |
| 增益（Gain） | 1.0-10.0 | 1.0 | 图像亮度增益倍数 | 仅在曝光调整无法满足需求时使用，过高增益会增加图像噪声 |
| 对比度（Contrast） | 0-255 | 128 | 图像对比度强度 | 根据场景明暗程度调整，工业场景建议150-200 |
| 饱和度（Saturation） | 0-255 | 128 | 图像颜色饱和度 | 字符识别场景建议降低饱和度（80-120），彩色缺陷检测建议保持默认 |
| 白平衡（White Balance） | 自动/手动（3000-7000K） | 自动 | 图像色温调整 | 工业照明环境下建议使用手动模式，匹配实际照明色温 |
| 焦点（Focus） | 自动/手动（0-100） | 自动 | 摄像头焦点距离 | 固定焦距场景建议使用手动模式锁定焦点，避免自动对焦波动 |

**参数调整技巧**：
- 点击「重置参数」按钮可恢复摄像头默认设置
- 点击「保存预设」可将当前参数保存为自定义预设，方便快速切换
- 支持批量参数配置：选择多个摄像头后，点击「批量配置」可同时调整所有选中摄像头的参数

#### 2.2 图像采集操作

##### 2.2.1 实时预览
1. 进入「实时监控」页面，系统默认显示所有已连接摄像头的缩略图
2. 在左侧设备列表中选择要查看的摄像头（可多选，最多同时预览4个摄像头）
3. 右侧面板会以全屏或分屏模式显示实时图像
4. **预览控制**：
   - 双击预览区域可切换全屏/窗口模式
   - 点击「刷新」按钮可重新连接摄像头
   - 点击「截图」按钮可快速保存当前预览图像

##### 2.2.2 单张图像采集
1. 在实时预览页面，确保摄像头连接正常且图像清晰
2. 点击「拍照」按钮，系统会立即保存当前图像
3. **采集选项**：
   - 自动命名：系统默认使用"设备名_时间戳.jpg"格式命名（如`Camera1_20240101120000.jpg`）
   - 自定义命名：可在设置中启用自定义命名规则，支持变量（如`{设备名}_{产品编号}_{时间戳}`）
   - 保存路径：默认保存到系统数据库，也可设置保存到本地目录或网络共享文件夹
4. 采集完成后，系统会弹出提示，并将图像添加到「历史记录」页面

##### 2.2.3 定时采集
用于按照设定的时间间隔自动采集图像，适用于长时间监控场景：

1. 在实时预览页面，点击「定时采集」按钮，打开定时采集设置对话框
2. **基本配置**：
   - 采集间隔：设置两次采集之间的时间间隔（支持秒、分、时单位，范围1秒-24小时）
   - 采集数量：设置总采集数量（0表示无限采集，直到手动停止）
   - 结束时间：设置采集的结束时间（与采集数量二选一）
3. **高级配置**：
   - 图像质量：设置保存图像的压缩质量（1-100，默认90）
   - 自动标记：启用后，系统会根据检测结果自动为采集的图像添加标签
   - 异常触发：可设置仅当检测到异常时才保存图像，减少无效数据存储
4. 点击「开始」启动定时采集，系统会在任务栏显示采集进度
5. 点击「停止」或到达结束时间/采集数量后，定时采集任务自动结束

**定时采集示例**：
- 生产线监控：设置每5秒采集一次，24小时不间断，仅保存异常图像
- 产品抽检：设置每10分钟采集一次，每次采集5张连续图像

##### 2.2.4 连续视频录制
用于录制连续的视频流，适用于需要记录完整过程的场景：

1. 在实时预览页面，点击「录制」按钮，打开视频录制设置对话框
2. **视频配置**：
   - 保存格式：支持MP4（默认，兼容性好）和AVI（无损，文件较大）
   - 视频质量：
     - 分辨率：与当前预览分辨率一致（可选择降低分辨率以减少文件大小）
     - 帧率：与当前摄像头帧率一致（可选择降低帧率）
     - 比特率：设置视频编码比特率（默认8Mbps，范围1-20Mbps）
   - 音频录制：如果摄像头支持音频，可选择同时录制音频
3. **存储配置**：
   - 保存路径：选择视频文件的保存位置
   - 文件分割：设置单个视频文件的最大时长（默认30分钟），超过后自动创建新文件
   - 磁盘空间监控：启用后，当磁盘空间不足20%时自动停止录制
4. 点击「开始录制」，系统开始录制视频，预览窗口会显示录制时长和文件大小
5. 再次点击「停止录制」结束录制，视频文件会自动保存并添加到「视频记录」页面

### 3. 高级功能

#### 3.1 虚拟摄像头支持

如果没有物理摄像头，可以使用虚拟摄像头进行系统测试和功能验证：

**Linux系统设置**：
```bash
# 安装虚拟摄像头驱动
!apt-get update && apt-get install -y v4l2loopback-dkms v4l2loopback-utils

# 加载驱动模块，创建2个虚拟摄像头设备
!modprobe v4l2loopback devices=2 video_nr=10,11 card_label="VirtualCam1","VirtualCam2" exclusive_caps=1

# 查看创建的虚拟摄像头
!v4l2-ctl --list-devices

# 使用ffmpeg将视频文件推送到虚拟摄像头
!ffmpeg -re -i test_video.mp4 -f v4l2 -vcodec rawvideo -pix_fmt yuv420p /dev/video10

# 或者将图像序列推送到虚拟摄像头
!ffmpeg -re -f image2 -i test_images/%04d.jpg -vcodec rawvideo -pix_fmt yuv420p /dev/video11
```

**Windows系统设置**：
1. 下载并安装虚拟摄像头软件（如OBS VirtualCam、ManyCam）
2. 打开虚拟摄像头软件，配置视频源（文件、图像序列或屏幕捕获）
3. 在系统中会自动创建一个新的摄像头设备

**MacOS系统设置**：
1. 使用Homebrew安装虚拟摄像头工具：`brew install youtube-dl ffmpeg v4l2loopback`
2. 或者使用OBS Studio的虚拟摄像头功能

创建虚拟摄像头后，在系统的「设备管理」页面可以像物理摄像头一样添加和使用。

#### 3.2 网络摄像头接入

支持通过多种协议接入网络摄像头，满足不同网络环境的需求：

##### 3.2.1 RTSP协议（推荐）
大多数网络摄像头和NVR设备支持RTSP协议，连接方式：
1. 在设备管理中添加摄像头
2. 设备路径填写RTSP URL，格式如下：
   ```
   # 基本格式
   rtsp://[用户名]:[密码]@[IP地址]:[端口]/[流路径]
   
   # 示例
   rtsp://admin:123456@192.168.1.100:554/stream1  # 海康威视摄像头
   rtsp://admin:123456@192.168.1.200:554/cam/realmonitor?channel=1&subtype=0  # 大华摄像头
   ```
3. 点击「测试连接」验证RTSP URL的可用性

##### 3.2.2 HTTP协议
部分网络摄像头支持通过HTTP协议访问视频流：
```
http://192.168.1.100:8080/video  # 示例HTTP视频流地址
```

##### 3.2.3 ONVIF协议
支持通过ONVIF协议自动发现和配置网络摄像头：
1. 在设备管理页面，点击「ONVIF扫描」按钮
2. 系统会自动扫描局域网内所有支持ONVIF协议的摄像头
3. 在扫描结果列表中选择要添加的摄像头，填写用户名和密码
4. 点击「添加选中设备」完成添加

**网络摄像头配置建议**：
- 确保摄像头和系统处于同一局域网或可通过公网访问
- 为网络摄像头设置固定IP地址，避免IP变化导致连接失败
- 对于公网访问的摄像头，建议启用HTTPS加密传输，确保数据安全
- 调整摄像头的码率和分辨率，平衡图像质量和网络带宽占用

#### 3.3 图像预处理功能

系统提供实时图像预处理功能，可在采集图像前对图像进行优化：

1. 在「实时监控」页面，点击「预处理」按钮，打开预处理设置面板
2. **预处理选项**：
   - **去噪**：选择高斯模糊、中值滤波或双边滤波，去除图像噪声
   - **增强**：
     - 直方图均衡化：提高图像对比度
     - 自适应直方图均衡化：局部对比度增强，保留细节
     - 锐化：增强图像边缘和细节
   - **转换**：
     - 灰度转换：将彩色图像转换为灰度图像
     - 二值化：将图像转换为黑白二值图像，便于字符识别
     - 颜色空间转换：支持RGB、HSV、Lab等颜色空间转换
   - **几何变换**：
     - 旋转：调整图像旋转角度
     - 镜像：水平/垂直镜像图像
     - 透视校正：校正图像的透视变形
3. 调整预处理参数，实时预览效果
4. 点击「应用到采集」，预处理效果将应用到后续采集的图像
5. 支持保存预处理预设，方便在不同场景下快速切换

### 4. 常见问题与解决方案

| 问题 | 可能原因 | 解决方案 |
|------|---------|---------|
| 摄像头无法连接 | 设备被占用、驱动问题、参数错误 | 1. 检查摄像头是否被其他程序占用<br>2. 重新安装摄像头驱动<br>3. 检查设备路径或URL是否正确<br>4. 重启摄像头设备 |
| 图像模糊 | 焦点未正确调整、光照不足、运动模糊 | 1. 手动调整摄像头焦点<br>2. 增加环境照明<br>3. 减小曝光时间或增加帧率<br>4. 使用图像增强预处理 |
| 图像颜色异常 | 白平衡设置错误、颜色空间问题 | 1. 调整摄像头白平衡参数<br>2. 检查颜色空间设置<br>3. 使用图像预处理的颜色校正功能 |
| 采集图像丢失 | 存储路径不可写、磁盘空间不足 | 1. 检查存储路径的写入权限<br>2. 清理磁盘空间<br>3. 启用磁盘空间监控功能 |
| 网络摄像头延迟高 | 网络带宽不足、码率设置过高 | 1. 降低摄像头的码率和分辨率<br>2. 优化网络环境，减少网络拥塞<br>3. 使用有线网络连接替代无线连接 |

## 二、智能检测模块

### 1. 功能概述
智能检测模块是系统的核心，利用深度学习模型对采集的工业图像进行实时分析和智能识别。该模块基于PyTorch框架开发，支持多种检测任务，包括：
- 产品缺陷检测（裂纹、变形、划痕等）
- 字符识别（OCR）和文本区域检测
- 物体计数和定位
- 表面质量检测

模块采用模块化设计，支持模型热切换、多模型融合和自定义检测规则，满足不同工业场景的检测需求。

### 2. 使用方法

#### 2.1 模型选择与加载

##### 2.1.1 模型管理界面

「模型管理」页面是模型操作的核心界面，包含以下功能：
- **模型列表**：显示所有已上传和内置的模型
- **模型详情**：查看模型名称、类型、版本、创建时间和性能指标
- **模型操作**：使用模型、上传模型、删除模型、优化模型

##### 2.1.2 预训练模型选择

系统内置了多种预训练模型，适用于不同的检测任务：

1. 进入「模型管理」页面
2. **浏览模型列表**，查看模型的详细信息：
   - **YOLOv5s**：轻量级目标检测模型，适用于实时检测场景
   - **YOLOv5m**：中等大小模型，平衡了检测精度和速度
   - **YOLOv5l**：大型模型，检测精度高，适用于复杂场景
   - **CRNN**：用于字符识别的循环神经网络模型
   - **EasyOCR**：多语言OCR模型，支持中文、英文等多种语言
3. 根据检测任务和硬件条件选择合适的模型
4. 点击「使用模型」按钮，系统会自动加载模型并应用到检测系统

##### 2.1.3 自定义模型加载

支持上传本地训练好的自定义模型：

1. 在「模型管理」页面，点击「上传模型」按钮
2. **模型文件要求**：
   - YOLO模型：支持.pt格式（PyTorch模型）
   - OCR模型：支持.pt或.onnx格式
   - 其他模型：需符合系统支持的模型格式
3. **填写模型信息**：
   - 模型名称：自定义名称（如"生产线缺陷检测模型_v2"）
   - 模型类型：选择模型类型（目标检测、OCR、分类等）
   - 模型描述：详细描述模型的用途、训练数据、性能指标等
   - 输入尺寸：模型要求的输入图像尺寸（如640×640）
4. **高级配置**：
   - 标签文件：上传模型对应的标签文件（.txt格式，每行一个类别名称）
   - 置信度阈值：设置模型默认的置信度阈值
   - GPU加速：选择是否启用GPU加速（需要CUDA支持）
5. 点击「保存」完成上传，系统会自动验证模型的完整性和可用性

##### 2.1.4 模型加载原理

模型加载的核心代码位于`src/backend/model_loader.py`：

```python
import torch
from models.experimental import attempt_load

def load_yolo_model(model_path, device):
    """加载YOLO模型"""
    # 加载模型
    model = attempt_load(model_path, map_location=device)
    # 设置模型为推理模式
    model.eval()
    # 获取模型的输入尺寸
    img_size = 640
    return model, img_size

def load_ocr_model(model_path, device):
    """加载OCR模型"""
    # 根据模型类型选择不同的加载方式
    if model_path.endswith('.onnx'):
        import onnxruntime
        session = onnxruntime.InferenceSession(model_path, 
                                              providers=['CUDAExecutionProvider' if device.type == 'cuda' else 'CPUExecutionProvider'])
        return session
    else:
        model = torch.load(model_path, map_location=device)
        model.eval()
        return model
```

#### 2.2 实时检测

##### 2.2.1 启动实时检测

1. 进入「实时监控」页面，选择要进行检测的摄像头
2. 在右侧「检测设置」面板中，进行以下配置：
   - **检测模型**：选择要使用的检测模型
   - **检测任务**：选择检测类型（目标检测、OCR、分类等）
   - **检测区域**：设置ROI（感兴趣区域），只对该区域进行检测，提高检测效率
3. 点击「开始检测」按钮，系统开始实时检测
4. 预览窗口会显示检测结果，包括检测框、类别标签和置信度

##### 2.2.2 检测参数详细说明

在「检测设置」面板中，可以调整以下关键参数：

| 参数名称 | 可调整范围 | 默认值 | 说明 | 最佳实践 |
|---------|-----------|-------|------|---------|
| 置信度阈值（Confidence Threshold） | 0.1-1.0 | 0.5 | 检测结果的置信度过滤，低于该值的结果会被过滤 | 实际生产中建议设置为0.7-0.8，减少误检 |
| IOU阈值（IOU Threshold） | 0.1-1.0 | 0.5 | 非极大值抑制（NMS）的IOU阈值，用于去除重叠检测框 | 一般设置为0.4-0.6，根据目标密度调整 |
| 检测类别选择 | 多选 | 全部 | 选择要检测的目标类别 | 根据实际需求选择，减少不必要的计算 |
| 输入尺寸 | 320-1280 | 640 | 模型输入图像的尺寸 | 小尺寸（320）：速度快，精度低<br>大尺寸（1280）：精度高，速度慢 |
| 批处理大小 | 1-16 | 1 | 一次处理的图像数量 | 实时检测建议设置为1，批量检测可设置为4-8 |
| GPU加速 | 开启/关闭 | 开启（如果支持） | 是否使用GPU进行推理 | 建议开启，推理速度可提升5-10倍 |
| 显示结果 | 开启/关闭 | 开启 | 是否在预览窗口显示检测结果 | 调试时开启，生产环境可根据需求关闭 |

##### 2.2.3 检测结果查看与分析

实时检测结果会在「实时监控」页面实时显示：

1. **可视化结果**：
   - **检测框**：用不同颜色的矩形框标记检测到的目标
   - **标签**：显示目标的类别名称和置信度（如"缺陷: 0.92"）
   - **颜色编码**：不同类别的目标使用不同颜色标记（可在设置中自定义）
   - **ROI区域**：用半透明矩形标记感兴趣区域

2. **统计信息**：
   - 检测帧率（FPS）：显示当前的检测速度
   - 目标数量：实时显示检测到的目标总数
   - 各类别数量：按类别统计检测到的目标数量
   - 检测耗时：显示图像预处理、模型推理和结果后处理的耗时

3. **历史记录**：
   - 检测结果会自动保存到「检测记录」页面
   - 可以查看历史检测记录，包括图像、检测结果和统计信息
   - 支持按时间、设备、检测结果等条件进行筛选

##### 2.2.4 实时检测的技术实现

实时检测的核心代码位于`src/backend/detection.py`：

```python
def detect_single_image(model, img, device, conf_thres=0.5, iou_thres=0.5, img_size=640):
    """单张图像检测"""
    # 图像预处理
    img_preprocessed = preprocess_image(img, img_size)
    img_preprocessed = img_preprocessed.to(device)
    
    # 模型推理
    with torch.no_grad():
        pred = model(img_preprocessed)[0]
    
    # 结果后处理
    pred = non_max_suppression(pred, conf_thres, iou_thres)
    
    # 结果转换为可视化格式
    result = postprocess_results(pred, img.shape)
    
    return result

def realtime_detection(camera_id, model, device, conf_thres=0.5, iou_thres=0.5):
    """实时检测"""
    cap = cv2.VideoCapture(camera_id)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # 检测图像
        result = detect_single_image(model, frame, device, conf_thres, iou_thres)
        
        # 可视化结果
        frame_with_result = visualize_result(frame, result)
        
        # 显示结果
        cv2.imshow('Real-time Detection', frame_with_result)
        
        # 按ESC键退出
        if cv2.waitKey(1) == 27:
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

#### 2.3 批量图像处理

##### 2.3.1 批量检测操作

用于对多张图像进行批量检测，支持高效处理大规模图像数据集：

1. **图像源选择**：
   - 「历史记录」页面：选择已采集的图像（支持按时间、设备、标签等条件筛选）
   - 「本地文件」：上传本地图像文件夹（支持拖放操作）
   - 「网络路径」：输入网络共享文件夹路径（支持SMB、FTP等协议）
   - 「数据库查询」：通过SQL查询语句从数据库中筛选图像

2. **批量检测设置**：
   1. 选择要检测的图像（支持多选，使用Ctrl/Cmd+A全选）
   2. 点击「批量检测」按钮，打开批量检测设置对话框
   3. **基本设置**：
      - 检测模型：选择要使用的检测模型（支持同时选择多个模型进行对比检测）
      - 检测参数：
        - 置信度阈值：0.1-1.0（默认0.5），过滤低置信度检测结果
        - IOU阈值：0.1-1.0（默认0.5），控制重叠检测框的合并
        - 输入尺寸：320-1280（默认640），调整模型输入分辨率
      - 输出格式：
        - CSV格式：适用于数据分析和表格处理
        - JSON格式：适用于与其他系统集成
        - XML格式：适用于VOC数据集格式
        - YOLO格式：适用于训练新的YOLO模型
        - COCO格式：适用于通用目标检测框架
   4. **高级设置**：
      - 多线程处理：
        - 线程数：1-CPU核心数（默认CPU核心数/2）
        - 批处理大小：1-32（默认4），根据GPU内存调整
      - 结果保存：
        - 保存检测后图像：选择是否保存带检测框的图像
        - 检测框样式：自定义检测框颜色、粗细、标签显示等
      - 自动导出：设置导出路径和导出条件（如仅导出异常结果）
      - 检测日志：选择是否记录详细的检测日志

3. **启动批量检测**：
   - 点击「开始检测」按钮，系统开始批量检测
   - 检测进度会实时显示：
     - 已检测数量/总数量
     - 预计完成时间
     - 当前检测速度（FPS）
     - 内存/CPU/GPU使用率
   - 支持暂停/继续检测和取消检测
   - 检测完成后，系统会生成检测报告，包含检测统计信息

##### 2.3.2 批量检测的技术实现

批量检测的核心代码位于`src/backend/batch_detection.py`：

```python
import os
import cv2
import torch
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

def batch_detect(images_list, model, device, conf_thres=0.5, iou_thres=0.5, img_size=640, batch_size=4):
    """批量图像检测"""
    results = []
    
    # 分批处理图像
    for i in tqdm(range(0, len(images_list), batch_size), desc="Batch Detection"):
        batch_images = images_list[i:i+batch_size]
        
        # 批量加载和预处理图像
        batch_tensor = []
        original_shapes = []
        
        for image_path in batch_images:
            img = cv2.imread(image_path)
            if img is None:
                continue
            
            original_shapes.append(img.shape)
            
            # 图像预处理
            img_preprocessed = preprocess_image(img, img_size)
            batch_tensor.append(img_preprocessed)
        
        if not batch_tensor:
            continue
        
        # 合并为批量张量
        batch_tensor = torch.stack(batch_tensor).to(device)
        
        # 模型推理
        with torch.no_grad():
            preds = model(batch_tensor)[0]
        
        # 结果后处理
        preds = non_max_suppression(preds, conf_thres, iou_thres)
        
        # 结果转换
        for j, pred in enumerate(preds):
            if pred is not None:
                result = postprocess_results(pred, original_shapes[j])
                results.append({
                    "image_path": batch_images[j],
                    "detections": result
                })
    
    return results

def multi_thread_detect(images_list, model, device, conf_thres=0.5, iou_thres=0.5, img_size=640, num_threads=4):
    """多线程批量检测"""
    results = []
    
    # 定义单线程检测函数
    def thread_detect(image_path):
        img = cv2.imread(image_path)
        if img is None:
            return None
        
        result = detect_single_image(model, img, device, conf_thres, iou_thres, img_size)
        return {
            "image_path": image_path,
            "detections": result
        }
    
    # 使用线程池进行检测
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = [executor.submit(thread_detect, img_path) for img_path in images_list]
        
        for future in tqdm(futures, desc="Multi-thread Detection"):
            result = future.result()
            if result is not None:
                results.append(result)
    
    return results
```

##### 2.3.2 检测结果导出

支持多种格式的检测结果导出：

1. 在「批量检测」页面或「检测记录」页面，选择要导出的检测结果
2. 点击「导出结果」按钮
3. **选择导出格式**：
   - **CSV格式**：适用于数据分析和表格处理
     ```csv
     图像ID,文件名,检测时间,目标数量,类别,置信度,X1,Y1,X2,Y2
     1,Camera1_20240101120000.jpg,2024-01-01 12:00:00,2,缺陷,0.92,100,200,300,400
     1,Camera1_20240101120000.jpg,2024-01-01 12:00:00,2,缺陷,0.85,500,600,700,800
     ```
   - **JSON格式**：适用于与其他系统集成
     ```json
     {
       "image_id": 1,
       "filename": "Camera1_20240101120000.jpg",
       "detection_time": "2024-01-01 12:00:00",
       "detections": [
         {
           "class": "缺陷",
           "confidence": 0.92,
           "bbox": [100, 200, 300, 400]
         }
       ]
     }
     ```
   - **XML格式**：VOC数据集格式，适用于模型训练
   - **YOLO格式**：YOLO数据集格式，包含检测框坐标和类别
4. 设置导出路径，点击「导出」完成

### 3. 高级功能

#### 3.1 多模型融合检测

支持同时使用多个模型进行检测，提高检测精度：

1. 在「模型管理」页面，选择多个要融合的模型
2. 点击「融合检测」按钮，打开融合检测设置对话框
3. **融合策略设置**：
   - **投票法**：多个模型对同一目标进行检测，超过半数模型检测到的目标才会被保留
   - **加权平均法**：根据模型的性能为每个模型分配权重，计算加权平均置信度
   - **NMS融合**：对所有模型的检测结果进行统一的非极大值抑制
4. **权重设置**：为每个模型设置权重（根据模型的性能指标）
5. 点击「应用融合」，系统会自动加载所有模型并应用融合策略

多模型融合的技术实现：

```python
def fuse_detections(results_list, fusion_strategy="weighted", weights=None):
    """融合多个模型的检测结果"""
    if fusion_strategy == "weighted":
        # 加权平均融合
        return weighted_fusion(results_list, weights)
    elif fusion_strategy == "voting":
        # 投票融合
        return voting_fusion(results_list)
    elif fusion_strategy == "nms":
        # NMS融合
        return nms_fusion(results_list)
    else:
        raise ValueError("Unknown fusion strategy")
```

#### 3.2 自定义检测规则

支持根据业务需求设置自定义检测规则：

1. 进入「设置」→「检测规则」页面
2. 点击「添加规则」按钮，打开规则设置对话框
3. **规则设置**：
   - 规则名称：自定义规则名称（如"大尺寸缺陷检测规则"）
   - 触发条件：
     - 检测结果条件：如"缺陷面积 > 100px²"、"置信度 < 0.6"
     - 时间条件：如"检测时间在8:00-18:00之间"
     - 设备条件：如"设备ID为Camera1"
   - 动作设置：
     - 警报级别：选择警报级别（信息、警告、严重）
     - 警报方式：选择警报方式（声音、弹窗、邮件通知）
     - 执行动作：如"保存图像"、"触发外部设备"、"发送通知"
4. 点击「保存」完成设置，规则会立即生效

#### 3.3 检测结果回调

支持设置检测结果的回调函数，与其他系统集成：

1. 在「设置」→「系统集成」页面，点击「添加回调」按钮
2. **回调设置**：
   - 回调URL：接收检测结果的API地址
   - 回调格式：选择回调数据的格式（JSON/XML）
   - 触发条件：选择触发回调的条件（所有检测结果、仅异常结果）
3. 点击「保存」完成设置
4. 检测结果会自动发送到指定的回调URL

回调数据格式示例：

```json
{
  "event_type": "detection_result",
  "timestamp": "2024-01-01T12:00:00.000Z",
  "device_id": "Camera1",
  "image_url": "http://192.168.1.100/images/Camera1_20240101120000.jpg",
  "results": [
    {
      "class": "缺陷",
      "confidence": 0.92,
      "bbox": [100, 200, 300, 400],
      "area": 40000
    }
  ],
  "is_normal": false
}
```

### 4. 性能优化建议

#### 4.1 推理速度优化

- **模型选择**：根据硬件条件选择合适大小的模型
  - 低性能设备：使用YOLOv5s等轻量级模型
  - 高性能设备：使用YOLOv5l等高精度模型
- **输入尺寸**：根据检测需求调整输入尺寸
  - 小目标检测：使用较大的输入尺寸（如1280×1280）
  - 大目标检测：使用较小的输入尺寸（如320×320）
- **GPU加速**：启用GPU加速（需要CUDA支持）
  - 可将推理速度提升5-10倍
- **半精度推理**：使用FP16半精度推理
  ```python
  model.half()  # 将模型转换为半精度
  img = img.half()  # 将图像转换为半精度
  ```
- **批处理**：批量检测时使用较大的批处理大小

#### 4.2 检测精度优化

- **数据增强**：增加训练数据的多样性
- **标签优化**：确保训练数据的标签准确
- **模型训练**：使用更大的数据集和更长的训练时间
- **后处理优化**：调整置信度阈值和IOU阈值
- **多模型融合**：使用多个模型进行融合检测

### 5. 常见问题与解决方案

| 问题 | 可能原因 | 解决方案 |
|------|---------|---------|
| 检测速度慢 | GPU加速未开启、模型过大、输入尺寸过大 | 1. 启用GPU加速<br>2. 使用更小的模型<br>3. 减小输入尺寸 |
| 检测精度低 | 模型不适合当前任务、置信度阈值设置不当 | 1. 选择更适合的模型<br>2. 调整置信度阈值<br>3. 重新训练模型 |
| 模型加载失败 | 模型文件损坏、GPU内存不足、模型格式不支持 | 1. 检查模型文件完整性<br>2. 清理GPU内存<br>3. 转换为支持的模型格式 |
| 检测结果不稳定 | 摄像头晃动、光照变化大、模型鲁棒性差 | 1. 固定摄像头<br>2. 增加环境照明<br>3. 训练更鲁棒的模型 |
| 内存占用过高 | 批处理大小过大、模型过大 | 1. 减小批处理大小<br>2. 使用更小的模型<br>3. 定期清理内存 |

## 三、数据标注模块

### 1. 功能概述
数据标注模块是工业检测系统的重要组成部分，用于创建和管理高质量的训练数据集。该模块支持多种标注模式，包括文本区域标注（用于目标检测）、OCR字符标注（用于光学字符识别）和合成数据生成（用于数据增强），为模型训练提供可靠的数据基础。

### 2. 使用方法

#### 2.1 文本区域标注

用于标注图像中文本区域的位置和类别，适用于YOLO等目标检测模型的训练。

##### 2.1.1 进入标注界面
1. 点击左侧导航栏中的「数据标注」菜单
2. 选择「文本区域标注」选项，进入文本区域标注界面

##### 2.1.2 导入待标注图像

支持多种图像导入方式：

1. **本地文件导入**：
   - 点击「导入图像」按钮
   - 选择单个图像文件或整个图像文件夹
   - 支持的图像格式：JPG、PNG、BMP、TIFF等
   - 点击「确定」完成导入

2. **从采集记录导入**：
   - 点击「从采集记录导入」按钮
   - 选择采集日期、设备ID和图像类型
   - 勾选要导入的图像（支持批量选择）
   - 点击「导入所选图像」

3. **网络路径导入**：
   - 点击「网络路径导入」按钮
   - 输入网络共享文件夹路径（如`\\192.168.1.100\images`）
   - 选择要导入的图像
   - 点击「导入」

##### 2.1.3 标注界面布局

标注界面分为四个主要区域：

1. **图像列表区（左侧）**：
   - 显示所有待标注的图像缩略图
   - 支持按文件名、导入时间、标注状态排序
   - 显示图像的标注状态（未标注、部分标注、已标注）

2. **图像预览区（中央）**：
   - 显示当前选中的图像
   - 支持缩放、平移、旋转等操作
   - 显示已标注的文本区域框和标签

3. **工具控制面板（顶部）**：
   - 标注工具：矩形框工具、多边形工具（可选）
   - 视图控制：缩放、平移、旋转按钮
   - 标注操作：保存、撤销、重做、删除按钮

4. **属性设置区（右侧）**：
   - 图像信息：显示图像文件名、尺寸、分辨率等
   - 标注属性：设置标注框的类别、颜色、置信度等
   - 快捷键提示：显示常用快捷键

##### 2.1.4 标注操作流程

1. **选择图像**：在左侧图像列表中点击要标注的图像
2. **绘制标注框**：
   - 点击顶部工具栏中的「矩形框」工具
   - 在图像预览区点击并拖动鼠标，绘制文本区域的矩形框
   - 松开鼠标后，标注框会自动生成
3. **设置标注属性**：
   - 在右侧属性设置区，选择或输入类别标签
   - 支持的标签类型：文本区域、字符、缺陷区域等
   - 可以为标注框设置自定义颜色和注释
4. **调整标注框**：
   - **调整大小**：拖动标注框的控制点
   - **调整位置**：拖动标注框的中心
   - **精确调整**：在属性设置区输入精确的坐标值（X、Y、宽度、高度）
5. **保存标注**：
   - 点击顶部工具栏中的「保存」按钮
   - 或使用快捷键Ctrl+S
   - 系统会自动保存当前图像的标注信息

##### 2.1.5 标注工具使用技巧

| 操作 | 快捷键 | 说明 |
|------|--------|------|
| 绘制矩形框 | R | 切换到矩形框工具 |
| 平移图像 | 空格键+拖动 | 按住空格键拖动鼠标平移图像 |
| 缩放图像 | 鼠标滚轮 | 向前滚动放大，向后滚动缩小 |
| 放大图像 | Ctrl++ | 放大图像 |
| 缩小图像 | Ctrl+- | 缩小图像 |
| 重置视图 | Ctrl+0 | 将图像重置为原始大小和位置 |
| 选择标注框 | 点击标注框 | 选择单个标注框 |
| 多选标注框 | Shift+点击 | 选择多个标注框 |
| 删除标注框 | Delete | 删除选中的标注框 |
| 复制标注框 | Ctrl+C | 复制选中的标注框 |
| 粘贴标注框 | Ctrl+V | 粘贴复制的标注框 |
| 撤销操作 | Ctrl+Z | 撤销上一步操作 |
| 重做操作 | Ctrl+Y | 重做上一步操作 |
| 保存标注 | Ctrl+S | 保存当前图像的标注信息 |
| 下一张图像 | PageDown | 切换到下一张图像 |
| 上一张图像 | PageUp | 切换到上一张图像 |

##### 2.1.6 高级标注功能

1. **批量标注**：
   - 选择多张图像（按住Ctrl键点击）
   - 点击「批量标注」按钮
   - 设置统一的标注参数（如标签、颜色）
   - 点击「应用」完成批量标注

2. **标注模板**：
   - 标注完成一张图像后，点击「保存为模板」
   - 选择其他相似图像，点击「应用模板」
   - 系统会自动复制模板图像的标注框位置
   - 根据实际情况调整标注框位置

3. **智能辅助标注**：
   - 点击「智能辅助」按钮
   - 系统会使用预训练模型自动检测文本区域
   - 人工检查并修正自动检测的结果
   - 可以调整辅助检测的置信度阈值

#### 2.2 OCR字符标注

用于标注文本区域内的具体字符内容，适用于光学字符识别模型（如CRNN、EasyOCR）的训练。

##### 2.2.1 进入OCR标注界面
1. 点击左侧导航栏中的「数据标注」菜单
2. 选择「OCR字符标注」选项，进入OCR字符标注界面

##### 2.2.2 加载待标注图像

OCR字符标注需要基于已完成文本区域标注的图像：

1. **从文本区域标注导入**：
   - 点击「从文本区域标注导入」按钮
   - 选择已完成文本区域标注的图像集
   - 点击「导入」完成加载

2. **直接导入图像**：
   - 点击「导入图像」按钮
   - 选择待标注的图像
   - 系统会自动检测图像中的文本区域（基于预训练模型）
   - 人工检查并修正自动检测的文本区域

##### 2.2.3 OCR标注操作流程

1. **选择图像**：在左侧图像列表中点击要标注的图像
2. **选择文本区域**：点击图像中的文本区域框
3. **输入字符内容**：
   - 系统会弹出字符输入框
   - 输入文本区域内的准确字符内容
   - 支持的字符类型：中文、英文、数字、符号等
4. **验证字符内容**：
   - 系统会自动检查输入的字符是否符合要求
   - 可以设置字符集限制（如仅允许数字和英文）
5. **保存标注**：
   - 点击「保存」按钮或按Enter键
   - 系统会自动保存当前文本区域的字符标注
   - 自动跳转到下一个未标注的文本区域

##### 2.2.4 批量OCR标注功能

支持使用自动识别功能进行批量字符标注，提高标注效率：

1. 选择多张图像（按住Ctrl键点击）
2. 点击「批量识别」按钮，打开批量识别设置对话框
3. **识别设置**：
   - 选择识别模型：系统内置的OCR模型
   - 置信度阈值：设置自动识别的置信度阈值（默认0.8）
   - 自动修正：启用后，系统会自动修正明显的识别错误
4. 点击「开始识别」，系统会自动对所选图像进行字符识别
5. **人工审核**：
   - 识别完成后，系统会显示识别结果
   - 人工检查并修正识别错误
   - 可以使用快捷键快速导航和修正

批量OCR标注的技术实现：

```python
def batch_ocr_recognition(image_list, model, device, conf_thres=0.8):
    """批量OCR识别"""
    results = []
    
    for image_path in image_list:
        # 读取图像
        img = cv2.imread(image_path)
        
        # 获取图像中的文本区域（从标注文件中读取）
        text_regions = load_text_regions(image_path)
        
        image_results = []
        for region in text_regions:
            # 提取文本区域图像
            x, y, w, h = region
            text_img = img[y:y+h, x:x+w]
            
            # OCR识别
            with torch.no_grad():
                pred = model(text_img.to(device))
                # 解码识别结果
                text = decode_prediction(pred)
                conf = calculate_confidence(pred)
            
            if conf >= conf_thres:
                image_results.append({
                    "bbox": [x, y, w, h],
                    "text": text,
                    "confidence": conf,
                    "is_auto": True
                })
        
        results.append({
            "image_path": image_path,
            "regions": image_results
        })
    
    return results
```

##### 2.2.5 OCR标注最佳实践

- **字符输入规范**：
  - 严格按照图像中的实际字符输入，包括大小写、空格和符号
  - 对于无法识别的字符，使用特定符号标记（如「#」）
  - 保持字符编码一致，建议使用UTF-8编码

- **提高标注效率**：
  - 使用快捷键提高标注速度（如Enter键保存，Tab键切换到下一个区域）
  - 启用自动识别功能，减少手动输入
  - 对于重复出现的文本模式，使用复制粘贴功能

- **保证标注质量**：
  - 标注完成后进行交叉检查
  - 定期抽样检查标注质量
  - 建立标注规范文档，确保团队成员标注标准一致

#### 2.3 合成数据生成

支持自动生成合成训练数据，解决数据不足和数据多样性问题。

##### 2.3.1 进入合成数据生成界面
1. 点击左侧导航栏中的「数据标注」菜单
2. 选择「合成数据生成」选项，进入合成数据生成界面

##### 2.3.2 配置合成参数

合成数据生成需要配置以下参数：

1. **文本源配置**：
   - **字符集选择**：
     - 内置字符集：数字、英文、中文、符号等
     - 自定义字符集：上传自定义字符集文件（.txt格式）
   - **文本长度范围**：设置生成文本的最小和最大长度
   - **文本内容类型**：选择文本类型（随机字符、固定格式、来自文本库）
   - **文本库**：上传文本库文件（.txt格式，每行一段文本）

2. **背景图像配置**：
   - **背景类型**：
     - 纯色背景：选择背景颜色
     - 图像背景：上传工业场景背景图像
     - 渐变背景：设置渐变颜色和方向
   - **背景增强**：
     - 模糊：设置背景模糊程度
     - 噪声：添加随机噪声
     - 纹理：添加工业纹理效果

3. **字体与样式配置**：
   - **字体文件**：
     - 内置字体：选择系统内置的字体
     - 自定义字体：上传字体文件（.ttf、.otf格式）
   - **字体属性**：
     - 字体大小范围：设置生成文本的字体大小范围
     - 字体颜色：选择或自定义字体颜色
     - 字体样式：粗体、斜体、下划线等

4. **变换与增强参数**：
   - **几何变换**：
     - 旋转角度：-15°到15°（随机）
     - 缩放比例：0.8到1.2（随机）
     - 倾斜角度：-10°到10°（随机）
   - **颜色变换**：
     - 亮度调整：-20到20
     - 对比度调整：-20到20
     - 饱和度调整：-20到20
   - **噪声与模糊**：
     - 噪声强度：0到10
     - 模糊程度：0到5
   - **透视变换**：添加随机透视变形

##### 2.3.3 生成合成数据

1. **设置生成数量**：输入要生成的合成图像数量
2. **设置输出路径**：选择合成图像的保存路径
3. **设置文件名格式**：自定义合成图像的文件名格式（支持变量如{时间戳}、{序号}）
4. **预览合成效果**：
   - 点击「生成预览」按钮
   - 系统会生成1-3张预览图像
   - 检查预览效果，调整参数
5. **开始生成**：点击「开始生成」按钮，系统开始生成合成数据
6. **查看生成进度**：
   - 系统会显示生成进度条
   - 显示已生成数量、剩余时间和当前状态
   - 支持暂停/继续生成

##### 2.3.4 合成数据的特点

- **自动标注**：生成的合成图像自动包含精确的标注信息（文本区域和字符内容）
- **多样性**：支持多种变换和增强，生成多样化的训练数据
- **可控性**：可以精确控制文本内容、字体、背景等参数
- **高效性**：快速生成大量高质量的训练数据

合成数据生成的技术实现：

```python
def generate_synthetic_data(config, output_path, num_images):
    """生成合成训练数据"""
    # 加载文本源
    text_generator = TextGenerator(config["text_source"])
    
    # 加载背景图像
    background_generator = BackgroundGenerator(config["background"])
    
    # 加载字体
    font_manager = FontManager(config["font"])
    
    for i in range(num_images):
        # 生成文本内容
        text = text_generator.generate_text()
        
        # 生成背景图像
        background = background_generator.generate_background()
        
        # 渲染文本到背景上
        result_image, annotations = render_text(
            background, text, font_manager, config["transforms"]
        )
        
        # 保存合成图像和标注
        image_path = os.path.join(output_path, f"synthetic_{i:06d}.jpg")
        cv2.imwrite(image_path, result_image)
        
        # 保存标注文件（YOLO格式）
        annotation_path = os.path.join(output_path, f"synthetic_{i:06d}.txt")
        save_yolo_annotation(annotation_path, annotations, result_image.shape)
        
        # 保存OCR标注文件
        ocr_annotation_path = os.path.join(output_path, f"synthetic_{i:06d}_ocr.txt")
        save_ocr_annotation(ocr_annotation_path, annotations)
```

### 3. 数据管理

#### 3.1 标注数据导出

支持将标注数据导出为多种格式，用于不同模型的训练：

1. 在「标注管理」页面，选择要导出的标注数据
2. 点击「导出数据」按钮，打开导出设置对话框
3. **选择导出格式**：
   - **YOLO格式**：
     - 适用于YOLO系列目标检测模型
     - 标注文件格式：每个图像对应一个.txt文件，每行一个标注
     - 坐标格式：归一化的中心坐标和宽高
     - 示例：`0 0.5 0.5 0.2 0.1`
   
   - **VOC格式**：
     - 适用于Faster R-CNN、SSD等目标检测模型
     - 标注文件格式：XML格式，包含图像信息和标注信息
     - 坐标格式：像素坐标
   
   - **COCO格式**：
     - 通用目标检测数据集格式
     - 标注文件格式：JSON格式，包含所有图像和标注信息
     - 支持复杂的标注类型（如多边形、关键点）
   
   - **自定义格式**：
     - 支持自定义标注文件格式
     - 可以设置字段分隔符、坐标格式等

4. **导出设置**：
   - 导出路径：选择导出文件的保存路径
   - 图像包含：选择是否包含图像文件
   - 标注统计：选择是否生成标注统计报告
   - 压缩导出：选择是否将导出文件压缩为ZIP格式

5. 点击「导出」完成导出操作

#### 3.2 标注数据统计与分析

在「标注管理」页面可以查看详细的标注数据统计信息：

1. **总体统计**：
   - 总图像数量
   - 已标注图像数量
   - 未标注图像数量
   - 标注完成率
   - 总标注框数量

2. **类别统计**：
   - 各类别标注框数量分布
   - 各类别标注框面积分布
   - 各类别标注框宽高比分布

3. **标注质量分析**：
   - 标注框重叠度分析
   - 标注框大小分布
   - 标注一致性检查

4. **标注进度监控**：
   - 每日标注数量趋势图
   - 各标注员标注数量统计
   - 标注任务完成进度

#### 3.3 标注数据版本管理

支持对标注数据进行版本管理，确保数据的可追溯性：

1. **创建版本**：
   - 在「标注管理」页面，点击「创建版本」按钮
   - 输入版本名称和版本描述
   - 选择要包含在版本中的标注数据
   - 点击「创建」完成版本创建

2. **版本比较**：
   - 选择两个版本进行比较
   - 系统会显示两个版本之间的差异
   - 包括新增、修改和删除的标注数据

3. **版本回滚**：
   - 选择要回滚的版本
   - 点击「回滚到该版本」按钮
   - 系统会将当前标注数据恢复到指定版本

### 4. 高级功能

#### 4.1 标注审核与质量控制

支持标注审核功能，确保标注数据的质量：

1. **进入审核界面**：
   - 点击「标注管理」菜单
   - 选择「标注审核」选项

2. **审核操作**：
   - 选择待审核的标注数据
   - 查看标注图像和标注信息
   - 审核结果：
     - 通过：标注质量符合要求
     - 拒绝：标注质量不符合要求，需要重新标注
     - 修正：部分标注需要修正

3. **质量评分**：
   - 为每个标注员的标注质量打分
   - 统计标注员的平均评分和质量趋势
   - 可以设置质量阈值，低于阈值的标注需要重新审核

#### 4.2 团队协作标注

支持多人团队协作进行数据标注：

1. **用户管理**：
   - 管理员可以添加和管理标注员用户
   - 设置用户角色和权限（标注员、审核员、管理员）

2. **任务分配**：
   - 管理员可以创建标注任务
   - 将任务分配给不同的标注员
   - 设置任务截止时间和质量要求

3. **进度监控**：
   - 管理员可以实时监控任务进度
   - 查看每个标注员的工作进度和质量
   - 可以调整任务分配，平衡工作负载

4. **数据共享**：
   - 支持标注数据的共享和协作编辑
   - 可以设置数据访问权限
   - 支持实时同步标注进度

#### 4.3 自动化标注辅助

支持使用AI模型进行自动化标注辅助，提高标注效率：

1. **预标注功能**：
   - 使用预训练模型对图像进行自动标注
   - 人工检查并修正自动标注结果
   - 可以调整自动标注的置信度阈值

2. **标注建议**：
   - 系统会根据已标注的数据提供标注建议
   - 支持自动补全类别标签
   - 支持相似图像的标注迁移

3. **错误检测**：
   - 自动检测标注错误（如重叠标注、错误标签）
   - 提供错误修正建议
   - 可以设置错误检测规则

### 5. 最佳实践与技巧

#### 5.1 标注质量保证

- **建立标注规范**：制定详细的标注规范文档，明确标注要求和标准
- **培训标注人员**：对标注人员进行培训，确保他们理解标注规范
- **定期审核**：定期对标注数据进行审核，确保标注质量
- **交叉验证**：使用多个标注员标注同一批数据，比较标注结果
- **质量反馈**：建立标注质量反馈机制，及时修正标注错误

#### 5.2 标注效率提升

- **使用快捷键**：熟练掌握标注快捷键，提高标注速度
- **批量操作**：充分利用批量标注功能，减少重复操作
- **模板复用**：对相似图像使用标注模板，提高标注效率
- **自动化辅助**：使用自动识别和预标注功能，减少手动标注工作量
- **合理组织数据**：按照类别和场景组织数据，提高标注效率

#### 5.3 数据多样性保障

- **多种场景**：确保标注数据包含多种工业场景
- **不同光照**：包含不同光照条件下的图像
- **不同角度**：包含不同拍摄角度的图像
- **不同质量**：包含不同清晰度和分辨率的图像
- **合成数据**：使用合成数据生成功能，增加数据多样性

### 6. 常见问题与解决方案

| 问题 | 可能原因 | 解决方案 |
|------|---------|---------|
| 标注框无法绘制 | 图像未加载完成、工具选择错误 | 1. 等待图像加载完成<br>2. 确保选择了正确的标注工具<br>3. 刷新页面重新加载 |
| 字符输入框无法显示 | 文本区域未选中、JavaScript错误 | 1. 确保正确点击了文本区域框<br>2. 检查浏览器控制台是否有错误<br>3. 刷新页面重新加载 |
| 批量识别结果不准确 | 识别模型不适合当前任务、置信度阈值设置不当 | 1. 选择更适合的识别模型<br>2. 调整置信度阈值<br>3. 重新训练识别模型 |
| 合成数据质量差 | 参数设置不当、字体和背景不匹配 | 1. 调整合成参数<br>2. 选择更适合的字体和背景<br>3. 增加变换和增强效果 |
| 标注数据导出失败 | 导出路径错误、权限不足、格式不支持 | 1. 检查导出路径是否正确<br>2. 确保有足够的写入权限<br>3. 选择支持的导出格式 |

## 四、模型训练模块

### 1. 功能概述
模型训练模块用于训练和优化工业检测模型，支持自定义模型架构和训练参数。

### 2. 使用方法

#### 2.1 训练数据准备

1. **选择训练数据集**
   - 进入「模型训练」页面
   - 点击「选择数据集」按钮
   - 选择已完成标注的数据集（支持YOLO/VOC/COCO等多种格式）
   - **数据集划分**：
     - 训练集比例：默认70%（用于模型训练）
     - 验证集比例：默认20%（用于训练过程中的模型评估）
     - 测试集比例：默认10%（用于最终模型性能测试）
     - 支持手动调整划分比例，或使用预设划分方案
   - **数据平衡检查**：系统会自动检测数据集类别分布，若存在严重不平衡会给出警告

2. **数据增强设置**
   - 在「数据增强」面板中，选择要使用的增强方法和参数：
     - **几何变换**：
       - 随机翻转：水平翻转（概率0.5）、垂直翻转（概率0.3）
       - 随机旋转：-15°到15°（随机角度）
       - 随机缩放：0.7到1.3（缩放比例）
       - 随机裁剪：0.8到1.0（裁剪比例）
       - 仿射变换：随机平移、旋转、缩放组合
     - **颜色变换**：
       - 亮度调整：-30到30（亮度值变化）
       - 对比度调整：-20到20（对比度变化）
       - 饱和度调整：-20到20（饱和度变化）
       - 色调调整：-10到10（色调变化）
     - **图像增强**：
       - 高斯模糊：kernel size 3×3到7×7（随机选择）
       - 高斯噪声：标准差0.01到0.1（随机生成）
       - 随机遮挡：随机区域像素置零（遮挡比例0.01到0.1）
       - 锐化：USM锐化增强边缘

   数据增强的技术实现：

   ```python
   # 数据增强示例代码
   import torchvision.transforms as transforms
   from PIL import Image

   # 训练集数据增强
   train_transform = transforms.Compose([
       # 随机大小裁剪
       transforms.RandomResizedCrop(size=640, scale=(0.7, 1.3)),
       # 随机水平翻转
       transforms.RandomHorizontalFlip(p=0.5),
       # 随机垂直翻转
       transforms.RandomVerticalFlip(p=0.3),
       # 随机旋转
       transforms.RandomRotation(degrees=(-15, 15)),
       # 颜色抖动
       transforms.ColorJitter(
           brightness=0.3,     # 亮度调整范围
           contrast=0.2,       # 对比度调整范围
           saturation=0.2,     # 饱和度调整范围
           hue=0.1             # 色调调整范围
       ),
       # 高斯模糊
       transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.5),
       # 转换为Tensor
       transforms.ToTensor(),
       # 标准化
       transforms.Normalize(
           mean=[0.485, 0.456, 0.406],
           std=[0.229, 0.224, 0.225]
       )
   ])

   # 验证集和测试集数据增强（只进行基本的图像变换）
   val_test_transform = transforms.Compose([
       transforms.Resize((640, 640)),
       transforms.ToTensor(),
       transforms.Normalize(
           mean=[0.485, 0.456, 0.406],
           std=[0.229, 0.224, 0.225]
       )
   ])
   ```

#### 2.2 模型配置

1. **选择模型架构**
   - 在「模型选择」下拉菜单中选择适合的模型架构：
     - **YOLOv5系列**：
       - YOLOv5s：轻量级模型（参数约7M），适合资源受限设备
       - YOLOv5m：中等大小模型（参数约21M），平衡速度和精度
       - YOLOv5l：大型模型（参数约47M），高精度检测
       - YOLOv5x：特大型模型（参数约87M），最高精度
     - **YOLOv7系列**：
       - YOLOv7：基础模型，高精度高性能
       - YOLOv7x：增强模型，更高的检测精度
       - YOLOv7-tiny：轻量化模型，适合边缘设备
     - **Custom（自定义模型）**：
       - 支持导入自定义模型架构文件（.yaml格式）
       - 可配置网络层数、通道数等参数
       - 支持自定义损失函数和评估指标

2. **训练参数设置**
   - **训练轮数（Epochs）**：
     - 建议范围：30-100轮
     - 小数据集：50-100轮（充分训练）
     - 大数据集：30-50轮（避免过拟合）
     - **早停策略**：验证集指标连续5轮不提升时自动停止
   - **批次大小（Batch Size）**：
     - 根据GPU内存动态调整：
       - 11GB GPU：16-32
       - 8GB GPU：8-16
       - 4GB GPU：4-8
     - **自动批次大小**：系统可根据GPU内存自动推荐合适的批次大小
   - **学习率（Learning Rate）**：
     - 基础学习率：默认0.001（AdamW）/ 0.01（SGD）
     - **学习率调度器**：
       - Cosine Annealing：余弦退火学习率下降
       - Step Decay：固定步长学习率下降
       - ReduceLROnPlateau：验证集指标停滞时降低学习率
   - **优化器（Optimizer）**：
     - **AdamW**：默认选项，收敛速度快，适合大多数任务
     - **SGD**：带动量的随机梯度下降，训练更稳定
     - **RMSprop**：自适应学习率优化器
   - **损失函数（Loss Function）**：
     - **CIoU Loss**：中心预测损失（默认）
     - **DIoU Loss**：距离IoU损失
     - **GIoU Loss**：广义IoU损失
     - **Focal Loss**：解决类别不平衡问题
   - **正则化参数**：
     - 权重衰减（Weight Decay）：0.0005（默认）
     - 梯度裁剪（Gradient Clipping）：防止梯度爆炸

   训练参数配置的技术实现：

   ```python
   # 训练参数配置示例
   training_config = {
       "epochs": 50,
       "batch_size": 16,
       "learning_rate": 0.001,
       "optimizer": "AdamW",
       "weight_decay": 0.0005,
       "scheduler": {
           "type": "CosineAnnealing",
           "T_max": 50,
           "eta_min": 0.00001
       },
       "loss_function": "CIoU",
       "early_stopping": {
           "patience": 5,
           "monitor": "val_map"
       },
       "gradient_clipping": 1.0
   }
   ```

3. **模型输出配置**
   - **保存路径设置**：指定模型保存的目录
   - **模型命名规则**：自动生成包含时间戳、模型类型和版本的文件名
   - **保存策略**：
     - 保存最佳模型（基于验证集指标）
     - 保存最后一轮模型
     - 保存每N轮模型（可设置保存间隔，默认10轮）
   - **导出格式**：训练过程中自动生成多种格式的模型文件
     - PyTorch模型（.pt）
     - TorchScript模型（.torchscript）
     - ONNX模型（.onnx）（可选）

#### 2.3 模型训练

1. **开始训练**
   - 配置完成后，点击「开始训练」按钮
   - 系统会自动启动训练过程
   - 可以在「训练监控」页面查看训练进度

2. **训练过程监控**
   - 实时显示训练损失（Loss）和验证指标
   - 显示学习率变化曲线
   - 显示训练和验证的准确率、精确率、召回率等指标
   - 可以暂停/继续训练
   - 可以提前终止训练

3. **训练结果分析**
   - 训练完成后，系统会自动生成训练报告
   - 报告包括：
     - 训练过程曲线
     - 模型性能指标
     - 混淆矩阵
     - 错误案例分析

#### 2.4 模型测试与部署

1. **模型测试**
   - 在「模型测试」页面，选择已训练完成的模型
   - 上传测试图像或选择测试数据集
   - 点击「开始测试」
   - 查看测试结果和性能指标

2. **模型导出**
   - 选择要导出的模型
   - 选择导出格式：
     - PyTorch模型（.pt）
     - ONNX格式（.onnx）
     - TensorRT引擎（.engine）
   - 设置导出参数
   - 点击「导出」完成

3. **模型部署**
   - 在「模型管理」页面，选择已训练完成的模型
   - 点击「部署模型」按钮
   - 选择部署位置（本地/云端）
   - 点击「确认部署」
   - 部署完成后，模型将自动应用到检测系统

### 3. 高级功能

#### 3.1 迁移学习

利用预训练模型进行迁移学习，加速训练过程：

1. 在「模型配置」页面，选择「使用预训练权重」
2. 选择要使用的预训练模型（如YOLOv5s.pt）
3. 设置冻结层数量（前N层不参与训练）
4. 开始训练

#### 3.2 模型压缩与优化

对训练好的模型进行压缩和优化，减小模型体积并提高推理速度：

1. 在「模型管理」页面，选择要优化的模型
2. 点击「模型优化」按钮
3. 选择优化方法：
   - 量化（Quantization）：INT8量化
   - 剪枝（Pruning）：去除冗余参数
   - 蒸馏（Distillation）：知识蒸馏
4. 设置优化参数
5. 点击「开始优化」

## 五、系统集成与API

### 1. RESTful API

系统提供完整的RESTful API接口，支持与其他系统集成：

- **摄像头控制API**：获取摄像头列表、开始/停止预览等
- **图像采集API**：单张拍照、定时采集等
- **检测API**：实时检测、批量检测等
- **标注API**：数据标注、导出等
- **模型API**：模型训练、测试、部署等

### 2. MES系统集成

支持与工业MES系统集成：

1. 在「设置」→「系统集成」页面
2. 配置MES系统连接参数
3. 设置数据同步规则
4. 启用自动同步功能

## 六、常见问题与解决方法

### 1. 图像采集问题

**问题**：摄像头无法正常连接
**解决**：
- 检查摄像头驱动是否安装正确
- 确认摄像头设备路径是否正确
- 检查摄像头是否被其他程序占用

### 2. 检测精度问题

**问题**：检测结果不准确，误检率高
**解决**：
- 调整置信度阈值
- 增加训练数据量
- 优化模型训练参数
- 考虑使用更适合的模型架构

### 3. 标注效率问题

**问题**：标注速度慢，效率低
**解决**：
- 使用自动标注功能
- 利用合成数据生成
- 采用多人协作标注

### 4. 模型训练问题

**问题**：模型训练过拟合
**解决**：
- 增加数据增强
- 减少训练轮数
- 增加正则化项
- 使用早停策略

## 七、联系方式

如果在使用过程中遇到问题，请联系技术支持：
- 邮箱：support@industrial-detection.com
- 电话：+86-123-4567-8910
- 文档：https://docs.industrial-detection.com
